---
layout: default
title: Настройка WhisperX ASR
parent: Руководство администратора
nav_order: 8
---

# Настройка сервиса WhisperX ASR

WhisperX — это продвинутый ASR (Automatic Speech Recognition) сервис, который предоставляет превосходную идентификацию говорящих и временные метки на уровне слов по сравнению со стандартными реализациями Whisper. Это руководство охватывает настройку WhisperX как альтернативного ASR-бэкенда для Speakr.

## Обзор

**Преимущества WhisperX:**
- ✅ Лучшая точность идентификации говорящих (Pyannote.audio 4.0)
- ✅ Более точные временные метки на уровне слов
- ✅ Улучшенная обработка нескольких говорящих
- ✅ Активная разработка и обновления
- ✅ Готовое к продакшену развертывание Docker

**vs. Стандартный Whisper ASR:**
- Стандартный: Простой, легковесный, хорош для одного говорящего
- WhisperX: Продвинутая идентификация говорящих, лучше для встреч/бесед

## Предварительные требования

### Требования к оборудованию

**Минимум:**
- NVIDIA GPU с 8 ГБ+ VRAM (RTX 3060, RTX 2080 и т.д.)
- 16 ГБ RAM
- 50 ГБ свободного дискового пространства

**Рекомендуется:**
- NVIDIA GPU с 16 ГБ+ VRAM (RTX 3080, RTX 4080, A100)
- 32 ГБ RAM
- 100 ГБ SSD хранилища

### Требования к программному обеспечению

- Docker и Docker Compose
- NVIDIA Container Toolkit
- Аккаунт Hugging Face с доступом к моделям

## Быстрый старт

### 1. Получите сервис WhisperX

Сервис WhisperX ASR поддерживается в отдельном репозитории:

```bash
# Клонируйте сервис WhisperX ASR
git clone https://github.com/murtaza-nasir/whisperx-asr-service.git
cd whisperx-asr-service
```

### 2. Настройте доступ Hugging Face

**Выполните ВСЕ шаги ниже для включения идентификации говорящих:**

#### Шаг 1: Создайте аккаунт
- Посетите: [https://huggingface.co/join](https://huggingface.co/join)
- Зарегистрируйтесь с вашей электронной почтой

#### Шаг 2: Примите соглашения моделей (КРИТИЧНО - ВСЕ ТРИ ТРЕБУЮТСЯ)

Вы должны принять соглашения для **всех трех моделей**, используемых конвейером идентификации говорящих:

1. **Основная модель идентификации говорящих:**
   - [https://huggingface.co/pyannote/speaker-diarization-community-1](https://huggingface.co/pyannote/speaker-diarization-community-1)

2. **Модель сегментации:**
   - [https://huggingface.co/pyannote/segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0)

3. **Идентификация говорящих 3.1:**
   - [https://huggingface.co/pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)

Для каждой модели:
- Нажмите кнопку **"Agree and access repository"**
- Заполните форму (Компания/университет: ваша организация, Случай использования: "Meeting note taker")
- Отправьте (одобрение мгновенное)

#### Шаг 3: Сгенерируйте токен доступа
- Посетите: [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
- Нажмите **"New token"**
- Имя: `whisperx-diarization`
- Разрешение: **Read**
- Нажмите **"Generate token"**
- Скопируйте токен (начинается с `hf_...`)

**⚠️ Важно:** Вы ДОЛЖНЫ принять соглашение модели в Шаге 2. Без этого вы получите ошибки "403 Access Denied" даже с действительным токеном.

### 3. Настройте окружение

```bash
# Скопируйте пример конфигурации
cp .env.example .env

# Отредактируйте и добавьте ваш токен Hugging Face
nano .env
```

Обновите `.env`:
```bash
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
DEVICE=cuda
COMPUTE_TYPE=float16
BATCH_SIZE=16
```

### 4. Разверните сервис

```bash
# Соберите Docker образ
docker compose build

# Запустите сервис
docker compose up -d

# Проверьте логи
docker compose logs -f
```

### 5. Протестируйте сервис

```bash
# Проверка здоровья
curl http://localhost:9000/health

# Должно вернуть:
{
  "status": "healthy",
  "device": "cuda",
  "loaded_models": []
}
```

## Интеграция с Speakr

### Развертывание на той же машине

Если WhisperX работает на той же машине, что и Speakr:

Обновите файл `.env` Speakr:

```bash
# Включить ASR эндпоинт
USE_ASR_ENDPOINT=true

# Указать на сервис WhisperX
ASR_BASE_URL=http://whisperx-asr-api:9000
```

Перезапустите Speakr:

```bash
docker compose restart
```

### Развертывание на отдельной GPU-машине

Если WhisperX находится на выделенном GPU-сервере:

**На GPU-машине:**

1. Откройте сервис для сети в `docker-compose.yml`:
   ```yaml
   ports:
     - "0.0.0.0:9000:9000"
   ```

2. Настройте файрвол:
   ```bash
   sudo ufw allow 9000/tcp
   ```

**На машине Speakr:**

Обновите `.env` Speakr:

```bash
USE_ASR_ENDPOINT=true
ASR_BASE_URL=http://GPU_MACHINE_IP:9000
```

Замените `GPU_MACHINE_IP` на фактический IP-адрес.

## Конфигурация

### Настройка производительности

Отредактируйте `.env` сервиса WhisperX:

**Высокопроизводительный GPU (RTX 3080+, A100):**
```bash
BATCH_SIZE=32
COMPUTE_TYPE=float16
```

**Средний GPU (RTX 3060, RTX 2080):**
```bash
BATCH_SIZE=16
COMPUTE_TYPE=float16
```

**Низкопроизводительный GPU (GTX 1660, RTX 2060):**
```bash
BATCH_SIZE=8
COMPUTE_TYPE=int8
```

### Выбор модели

Модели выбираются для каждой записи в Speakr. Доступные опции:

| Модель | Качество | Скорость | Требуется VRAM |
|--------|----------|----------|----------------|
| tiny | Низкое | Самая быстрая | 1 ГБ |
| base | Низкое | Очень быстрая | 1 ГБ |
| small | Среднее | Быстрая | 2 ГБ |
| medium | Хорошее | Умеренная | 5 ГБ |
| large-v2 | Отличное | Медленная | 10 ГБ |
| large-v3 | Лучшее | Медленная | 10 ГБ |

**Рекомендация:** Используйте `large-v3` для лучшего качества, `small` для скорости.

## Идентификация говорящих

WhisperX предоставляет превосходную идентификацию говорящих по сравнению со стандартными реализациями.

### Настройки в Speakr

При загрузке или обработке записей:

- **Min Speakers:** Минимальное ожидаемое количество говорящих
- **Max Speakers:** Максимальное ожидаемое количество говорящих
- Оставьте пустым для автоматического обнаружения

**Советы:**
- Установите `min_speakers=2` и `max_speakers=6` для типичных встреч
- Для интервью: `min_speakers=2`, `max_speakers=2`
- Для панелей: `min_speakers=3`, `max_speakers=8`

### После транскрибации

Используйте функцию идентификации говорящих Speakr для назначения реальных имен обнаруженным говорящим. Улучшенная идентификация говорящих WhisperX делает это более точным.

## Мониторинг

### Проверка здоровья сервиса

```bash
# Статус контейнера
cd /path/to/whisperx-asr-service
docker compose ps

# Просмотр логов
docker compose logs -f

# Проверка использования GPU
nvidia-smi -l 1
```

### Метрики производительности

Отслеживайте в административном интерфейсе Speakr:
- Времена транскрибации
- Частоты ошибок
- Статистика использования моделей

## Решение проблем

### Сервис WhisperX не запускается

**Проверьте логи:**
```bash
docker compose logs whisperx-asr
```

**Распространенные проблемы:**
- GPU недоступен: Проверьте, что `nvidia-smi` работает
- Недействительный HF_TOKEN: Проверьте токен и соглашения моделей
- Конфликт портов: Измените порт в `docker-compose.yml`

### Speakr не может подключиться

**Протестируйте подключение:**
```bash
curl http://ASR_BASE_URL/health
```

**Решения:**
- Проверьте правила файрвола
- Проверьте сетевое подключение
- Убедитесь, что сервис запущен
- Попробуйте IP-адрес вместо имени хоста

### Медленная обработка

**Решения:**
- Увеличьте `BATCH_SIZE` (если у GPU есть память)
- Используйте меньшую модель (`small` вместо `large-v3`)
- Отключите идентификацию говорящих для более быстрой обработки
- Проверьте использование GPU с `nvidia-smi`

### Нехватка памяти

**Ошибка:** `CUDA out of memory`

**Решения:**
1. Уменьшите `BATCH_SIZE`: Установите в `8` или `4`
2. Используйте меньшую модель
3. Используйте `COMPUTE_TYPE=int8`
4. Закройте другие GPU-приложения

### Идентификация говорящих терпит неудачу

**Проверьте:**
1. HF_TOKEN установлен правильно в `.env`
2. Приняты соглашения моделей pyannote
3. Сервис имеет доступ к интернету (для первоначальной загрузки моделей)

**Решения:**
- Регенерируйте HF токен
- Примите соглашения моделей снова
- Проверьте логи на конкретные ошибки

## Обновление

### Обновление сервиса WhisperX

```bash
cd /path/to/whisperx-asr-service

# Получите последние изменения (если используете Git)
git pull

# Пересоберите образ
docker compose build --no-cache

# Перезапустите сервис
docker compose up -d
```

### Обновление моделей

Модели кешируются автоматически. Чтобы использовать более новые модели:

```bash
# Удалите том кеша
docker compose down -v

# Перезапустите (модели перезагрузятся)
docker compose up -d
```

## Соображения безопасности

### Для продакшена

1. **Используйте HTTPS:** Разверните за обратным прокси с SSL
2. **Правила файрвола:** Ограничьте доступ только к машине Speakr
3. **Аутентификация API:** Добавьте проверку ключа API
4. **Управление секретами:** Используйте Docker secrets для HF_TOKEN
5. **Регулярные обновления:** Поддерживайте сервис обновленным ежемесячно

### Пример правила файрвола

Разрешить только с машины Speakr:

```bash
sudo ufw allow from SPEAKR_IP to any port 9000
sudo ufw deny 9000/tcp
```

## Бенчмарки производительности

Протестировано на RTX 3080 (10 ГБ VRAM):

| Модель | 10 мин аудио | Время обработки | Фактор реального времени |
|--------|--------------|-----------------|-------------------------|
| small | 10 мин | 45 сек | 13x |
| medium | 10 мин | 90 сек | 6.7x |
| large-v3 | 10 мин | 180 сек | 3.3x |

*С идентификацией говорящих: добавьте ~30% времени обработки*

## Сравнение: WhisperX vs Стандартный Whisper

| Функция | Стандартный Whisper | WhisperX |
|---------|---------------------|----------|
| Качество транскрибации | Отличное | Отличное |
| Временные метки слов | Хорошее | Отличное |
| Идентификация говорящих | Хорошее | Отличное |
| Сложность настройки | Низкая | Средняя |
| Использование ресурсов | Ниже | Выше |
| Активная разработка | Умеренная | Высокая |
| Готовность к продакшену | Да | Да |

## Лучшие практики

1. **Начните с маленькой модели** для проверки настройки
2. **Отслеживайте память GPU** во время первых запусков
3. **Используйте кеширование моделей** через Docker volumes
4. **Установите соответствующее количество говорящих** для лучшей идентификации
5. **Регулярные резервные копии** тома кеша
6. **Отслеживайте логи** на ошибки
7. **Обновляйте ежемесячно** для последних улучшений

## Получение помощи

- **Документация сервиса:** См. README сервиса WhisperX
- **Проблемы WhisperX:** [GitHub](https://github.com/m-bain/whisperX/issues)
- **Интеграция Speakr:** Проверьте логи Speakr и административную панель

---

Для подробных инструкций по настройке см. [Руководство по настройке сервиса WhisperX](https://github.com/murtaza-nasir/whisperx-asr-service/blob/main/SETUP_GUIDE.md).
