# Часто задаваемые вопросы

Это вопросы, которые чаще всего возникают, когда люди начинают использовать Speakr. Ответы здесь сэкономят ваше время и помогут понять, как получить максимум от платформы.

## Общие вопросы

### Что такое Speakr?

Speakr — это веб-приложение с самостоятельным размещением, которое превращает ваши аудиозаписи в организованные, доступные для поиска и интеллектуальные заметки. Оно объединяет [транскрибацию](features.md#core-transcription-features), [ИИ-суммирование](features.md#automatic-summarization), [идентификацию говорящих](features.md#speaker-diarization) и [семантический поиск](user-guide/inquire-mode.md) в единую платформу, которую вы полностью контролируете. Если вы самостоятельно размещаете ASR-модель, такую как Whisper-эндпоинт или рекомендуемый ASR-сервис, и совместимый с OpenAI API для LLM, ваши данные никогда не покидают вашу инфраструктуру, давая вам полную приватность и контроль.

### Чем Speakr отличается от других сервисов транскрибации?

Ключевое отличие — самостоятельное размещение — вы запускаете Speakr на своем собственном сервере, сохраняя полный контроль над вашими данными. Помимо приватности, Speakr интегрирует транскрибацию с функциями на основе ИИ, такими как [интеллектуальное суммирование](features.md#automatic-summarization), [интерактивный чат](user-guide/transcripts.md) с вашими записями и [семантический поиск](user-guide/inquire-mode.md) по всему вашему контенту. Речь идет не только о преобразовании речи в текст; речь идет о том, чтобы сделать этот текст полезным и доступным.

### Какие аудиоформаты поддерживает Speakr?

Speakr обрабатывает большинство распространенных аудиоформатов, включая MP3, WAV, M4A, OGG, FLAC и другие. Система использует FFmpeg внутри для обработки аудио, поэтому по сути любой формат, поддерживаемый FFmpeg, будет работать. Видеофайлы, содержащие аудиодорожки, также поддерживаются — Speakr извлечет и обработает аудиокомпонент.

### Могут ли несколько человек использовать один и тот же экземпляр Speakr?

Да, Speakr разработан как многопользовательская система. У каждого пользователя есть свой аккаунт с отдельными записями, настройками и библиотеками говорящих. Администраторы могут [создавать и управлять учетными записями пользователей](admin-guide/user-management.md). См. [системную статистику](admin-guide/statistics.md) для мониторинга использования, мониторинга использования и настройки системных параметров. Пользователи не могут видеть записи друг друга, если они явно не обменяны через [ссылки для обмена](user-guide/sharing.md). Узнайте о [безопасности обмена](user-guide/sharing.md#security-and-privacy-considerations).

## Установка и настройка

### Каковы минимальные системные требования?

Speakr комфортно работает на скромном оборудовании. Вам нужно не менее 2 ГБ оперативной памяти, хотя 4 ГБ рекомендуется для лучшей производительности. Требования к процессору зависят от вашего использования — двухъядерный процессор хорошо справляется с однопользовательскими экземплярами, в то время как загруженные многопользовательские установки выигрывают от большего количества ядер. Потребности в хранилище зависят от объема ваших записей, но начните с не менее 20 ГБ свободного места для приложения и начальных записей.

### Нужно ли знать Docker для установки Speakr?

Базовые знания Docker помогают, но не обязательны. [Руководство по быстрому старту](getting-started.md) предоставляет точные команды для копирования и запуска. Для производственных развертываний см. [руководство по установке](getting-started/installation.md). Вам нужно установить Docker и Docker Compose на вашем сервере, создать файл конфигурации с вашими API-ключами, а затем запустить одну команду, чтобы запустить все. Самая сложная часть обычно — получение ваших API-ключей от OpenAI или OpenRouter.

### Могу ли я запустить Speakr на Raspberry Pi?

Да, Speakr может работать на Raspberry Pi 4 или новее с не менее 4 ГБ оперативной памяти. Производительность не будет соответствовать полноценному серверу, особенно для обработки транскрибации, но это вполне пригодно для личного использования. Образы Docker, совместимые с ARM, работают из коробки. Просто будьте терпеливы с более длительным временем обработки для больших записей.

### Могу ли я использовать ASR-веб-сервис для идентификации говорящих на Mac?

Необязательный ASR-веб-сервис (`onerahmet/openai-whisper-asr-webservice`), который предоставляет [идентификацию говорящих](features.md#speaker-diarization), имеет особые требования на macOS:

**Ограничение GPU**: Проброс GPU не работает на macOS, потому что Docker запускает контейнеры внутри виртуальной машины Linux. Это фундаментальное ограничение Docker на Mac.

**Решение**: Используйте стандартный образ CPU вместо версии GPU:
- Используйте `onerahmet/openai-whisper-asr-webservice:latest` (НЕ `:latest-gpu`)
- Тег `:latest` предоставляет обе архитектуры amd64 (Intel) и arm64 (Apple Silicon)
- Обработка будет медленнее без ускорения GPU, но полностью функциональна

Пример конфигурации для Mac:
```bash
docker run -d -p 9000:9000 \
  -e ASR_MODEL=base \
  -e ASR_ENGINE=whisperx \
  -e HF_TOKEN=your_huggingface_token \
  onerahmet/openai-whisper-asr-webservice:latest
```

Примечание: Если вам не нужна идентификация говорящих в ваших транскрипциях, вы можете использовать Speakr со стандартным API Whisper вместо этого, что не требует этого дополнительного контейнера.

### Как создать резервную копию моих данных Speakr?

Ваши данные Speakr состоят из трех основных компонентов: база данных SQLite в директории `instance/`, аудиофайлы и транскрипции в директории `uploads/`, и ваша конфигурация в файле `.env`. Чтобы создать полную резервную копию, сначала остановите контейнер, чтобы обеспечить согласованность базы данных, затем создайте резервную копию всех трех директорий:

```bash
docker compose down
tar czf speakr_backup_$(date +%Y%m%d).tar.gz uploads/ instance/ .env
docker compose up -d
```

Регулярные автоматические резервные копии настоятельно рекомендуются для производственного использования.

## Транскрибация и функции ИИ

### Насколько точна транскрибация?

Точность транскрибации зависит от нескольких факторов — качества аудио, четкости говорящего, фонового шума и технической лексики. См. [руководство по решению проблем](troubleshooting.md#poor-transcription-quality) для советов. Настройте [пользовательские промпты](admin-guide/prompts.md) для технической лексики. При хорошем аудио ожидайте 90-95% точности для четкой английской речи. Точность снижается при сильных акцентах, нескольких перекрывающихся говорящих или плохом качестве записи. ASR-эндпоинт с идентификацией говорящих часто обеспечивает лучшую практическую пригодность, даже если исходная точность аналогична.

### В чем разница между API Whisper и ASR-эндпоинтами?

API Whisper предоставляет базовую транскрибацию — преобразование речи в текст без идентификации говорящих. [Рекомендуемый ASR-контейнер](getting-started.md#option-b-custom-asr-endpoint-configuration) (`onerahmet/openai-whisper-asr-webservice`) предлагает расширенные функции, такие как [идентификация говорящих](features.md#speaker-diarization), которая идентифицирует и маркирует разных говорящих в беседе. Узнайте, как [управлять говорящими](user-guide/transcripts.md#speaker-identification) после транскрибации. Идентификация говорящих необходима для встреч с несколькими участниками, в то время как API Whisper хорошо работает для одноголосых записей, таких как диктовки или подкасты.

**Примечание о ASR-движках**: Для правильной работы идентификации говорящих с ASR-веб-сервисом вы должны использовать `ASR_ENGINE=whisperx`, а не `faster_whisper`. Хотя faster_whisper предоставляет транскрибацию, он не поддерживает идентификацию говорящих.

### Может ли Speakr транскрибировать языки, отличные от английского?

Да, Speakr поддерживает несколько языков через свои сервисы транскрибации. Модели Whisper обрабатывают десятки языков с различной точностью — основные языки, такие как испанский, французский, немецкий и китайский, работают хорошо, в то время как менее распространенные языки могут иметь сниженную точность. Установите предпочитаемый язык в [настройках аккаунта](user-guide/settings.md#language-preferences) или оставьте пустым для автоматического определения. См. [детали поддержки языков](features.md#language-support).

**Важно для китайской транскрибации**: При использовании ASR-эндпоинтов для китайского аудио избегайте использования дистиллированных моделей (например, distil-large-v3), так как они могут неправильно распознавать китайский как английский. Используйте полную модель large-v3 или аналогичные недистиллированные модели для точной китайской транскрибации.

### Как долго могут быть мои записи?

Нет жесткого ограничения на длину записи, но применяются практические соображения. Очень длинные записи (более 2-3 часов) занимают больше времени на обработку, используют больше API-кредитов и могут сделать интерфейс медленным. Лимит загрузки файлов по умолчанию составляет 300 МБ, что вмещает несколько часов сжатого аудио. Для очень длинного контента, такого как целые дневные семинары, рассмотрите разделение на логические сегменты.

### Какая модель ИИ генерирует сводки?

Генерация сводок использует языковую модель, настроенную в вашем [файле окружения](getting-started.md#step-3-configure-your-transcription-service). Настройте сводки с помощью [ИИ-промптов](admin-guide/prompts.md) — через локальный LLM-эндпоинт или облачного провайдера, такого как OpenAI или OpenRouter. Выбор модели влияет на [качество сводки](features.md#automatic-summarization), стоимость и скорость обработки. Мониторьте производительность в [системной статистике](admin-guide/statistics.md).

## Приватность и безопасность

### Действительно ли мои данные приватны?

При правильном самостоятельном размещении ваше аудио и транскрипции никогда не покидают ваш сервер. Однако API транскрибации и суммирования (OpenAI, OpenRouter) обрабатывают ваш контент на своих серверах. Для полной приватности вам нужно использовать локальные модели как для транскрибации, так и для суммирования, что требует значительных вычислительных ресурсов.

### Могу ли я использовать Speakr для конфиденциальных деловых встреч?

Да, с соответствующими мерами предосторожности. Самостоятельное размещение сохраняет данные под вашим контролем, но учитывайте политики данных вашего провайдера API. OpenAI и OpenRouter имеют разные политики хранения и использования данных. Для максимальной безопасности используйте локальные модели транскрибации и суммирования, хотя это требует мощного оборудования и технических знаний.

### Безопасны ли ссылки для обмена?

[Ссылки для обмена](user-guide/sharing.md) используют криптографически безопасные случайные токены, которые невозможно угадать. Управляйте общими записями с [панели управления обменом](user-guide/sharing.md#managing-your-shared-recordings). Однако любой, у кого есть ссылка, может получить доступ к общему контенту без аутентификации. Относитесь к ссылкам для обмена как к паролям — отправляйте их только через безопасные каналы и отзывайте доступ, когда он больше не нужен. Для чувствительного контента рассмотрите альтернативные методы обмена, которые требуют аутентификации.

### Кто может видеть мои записи?

По умолчанию только вы можете видеть ваши записи. [Пользователи-администраторы](admin-guide/user-management.md) не могут напрямую просматривать записи других пользователей через интерфейс, хотя они могут отслеживать [паттерны использования](admin-guide/statistics.md), хотя у них есть доступ к базе данных, который теоретически может это позволить. Общие записи доступны любому, у кого есть ссылка для обмена. Другие пользователи в том же экземпляре Speakr не могут видеть ваши записи, если вы явно не поделитесь ими.

## Функции и функциональность

### Что такое режим Inquire?

[Режим Inquire](user-guide/inquire-mode.md) — это функция семантического поиска Speakr, которая позволяет находить информацию по всем вашим записям, используя вопросы на естественном языке. [Векторное хранилище](admin-guide/vector-store.md) должно быть настроено для работы этой функции. Вместо поиска точных ключевых слов вы можете задавать вопросы типа "Что мы решили по поводу маркетингового бюджета?" и получать релевантные выдержки из любой записи, которая обсуждала эту тему. Он использует ИИ-эмбеддинги для понимания значения и контекста.

### Как работают профили говорящих?

Когда вы [идентифицируете говорящих](user-guide/transcripts.md#speaker-identification) в транскрипции, нажимая на общие метки (SPEAKER_01 и т.д.) и назначая имена, Speakr сохраняет их как профили говорящих. Управляйте ими в [настройках аккаунта](user-guide/settings.md#speakers-management-tab). В будущих обновлениях мы намерены добавить функциональность, чтобы записи могли использовать эти профили для автоматического предложения идентичностей говорящих на основе голосовых характеристик. Со временем вы создаете библиотеку распознанных говорящих, что делает транскрипции с несколькими людьми намного более полезными.

### Могу ли я редактировать транскрипции после их генерации?

Да, транскрипции полностью редактируемы. Нажмите кнопку Edit над любой транскрипцией, чтобы внести исправления. См. [руководство по транскриптам](user-guide/transcripts.md#editing-transcriptions) для опций редактирования. Это особенно полезно для исправления неправильно распознанных технических терминов, собственных имен или исправления назначений говорящих. Ваши правки сохраняются — они не будут потеряны, если вы регенерируете сводку или используете [функцию чата](user-guide/transcripts.md). Экспортируйте отредактированные транскрипты, используя [различные форматы](user-guide/transcripts.md).

### Какие форматы экспорта доступны?

Speakr может экспортировать записи в нескольких форматах. Копируйте транскрипции напрямую в буфер обмена для вставки в другие приложения. Узнайте об [опциях экспорта](features.md#export-options) и [обмене](user-guide/sharing.md). Загружайте полные записи как документы Word (.docx), включая транскрипцию, сводку и заметки. [Ссылки для обмена](user-guide/sharing.md) предоставляют доступ только для чтения через веб. Настройте, что видно в [настройках обмена](user-guide/sharing.md#creating-a-share-link). История чата также может быть экспортирована для целей документации.

## Решение проблем

### Почему транскрибация занимает так много времени?

Несколько факторов влияют на скорость транскрибации — размер файла, нагрузка на API-сервис, скорость сети и выбор модели. Большие файлы естественно занимают больше времени. API-сервисы могут замедляться во время пикового использования. Медленные интернет-соединения создают узкие места при загрузке аудио. Использование более крупных, более точных моделей, таких как Whisper Large, занимает больше времени, чем меньшие модели.

### Мои записи застряли в статусе "pending"

Обычно это означает, что фоновый процессор остановился или столкнулся с ошибкой. Проверьте логи Docker на наличие сообщений об ошибках. См. [руководство по решению проблем](troubleshooting.md#transcription-never-starts) для деталей. Мониторьте обработку в [векторном хранилище](admin-guide/vector-store.md). Распространенные причины включают недействительные API-ключи, превышенные квоты API или проблемы с сетевым подключением. Перезапуск контейнера часто решает временные проблемы. Проверьте панель управления вашего провайдера API на лимиты использования или проблемы с выставлением счетов.

### Почему все говорящие отображаются как "UNKNOWN_SPEAKER"?

Это распространенная проблема, когда идентификация говорящих настроена неправильно. Вот как это исправить:

1. **Проверьте ASR_ENGINE**: Убедитесь, что вы используете `ASR_ENGINE=whisperx` в вашем ASR-контейнере, а не `faster_whisper`
2. **Проверьте ASR_DIARIZE**: Хотя это установлено в `true` по умолчанию, когда `USE_ASR_ENDPOINT=true`, явно установите `ASR_DIARIZE=true` в вашем файле .env
3. **Токен HuggingFace**: ASR-контейнеру нужна действительная переменная окружения `HF_TOKEN` для загрузки моделей идентификации говорящих
4. **Сеть Docker**: Если контейнеры находятся в одном docker-compose, используйте имя контейнера (например, `http://whisper-asr:9000`), а не localhost или внешние IP
5. **Проверьте логи**: Ищите сообщения pyannote/VAD в логах вашего ASR-контейнера, чтобы подтвердить, что идентификация говорящих активна

ASR-сервис должен возвращать метки говорящих, такие как "SPEAKER_00", "SPEAKER_01" в транскрипции. Затем вы можете [идентифицировать этих говорящих](user-guide/transcripts.md#speaker-identification) с реальными именами.

### Почему я не могу делиться записями?

[Обмен](user-guide/sharing.md) требует, чтобы ваш экземпляр Speakr был доступен из интернета с шифрованием HTTPS/SSL. Проверьте [требования для обмена](user-guide/sharing.md#requirements-for-sharing) и [решение проблем](troubleshooting.md#sharing-links-dont-work). Локальные установки или настройки без HTTPS не могут генерировать рабочие ссылки для обмена. Система отключает функции обмена, когда эти требования не выполнены. Чтобы включить обмен, разверните Speakr на публичном сервере с доменным именем и SSL-сертификатом.

### Интерфейс медленный с большими транскрипциями

Браузеры с трудом отображают очень большие объемы текста, особенно в пузырьковом виде с идентификацией говорящих. Для записей более 2 часов рассмотрите использование простого вида вместо пузырькового вида. Очистите кеш браузера, если производительность ухудшается со временем. Разделение очень длинных записей на сегменты улучшает как производительность, так и удобство использования.

## Лучшие практики

### Как мне организовать мои записи?

Разработайте последовательную [систему тегов](user-guide/settings.md#tag-management-tab) рано. Создавайте теги для разных проектов, типов встреч или клиентов. Теги могут включать [пользовательские промпты](admin-guide/prompts.md) для специализированной обработки. Используйте описательные заголовки, которые помогут вам найти записи через месяцы. Добавляйте заметки сразу после записей, пока контекст свеж. Регулярное обслуживание — архивирование старых записей и очистка тестовых файлов — поддерживает вашу библиотеку управляемой.

### Нужно ли мне информировать людей, что их записывают?

Юридические требования различаются в зависимости от юрисдикции. Многие регионы требуют явного согласия от всех сторон, которые записываются. Speakr включает настраиваемую функцию [отказа от ответственности при записи](admin-guide/system-settings.md#recording-disclaimer). См. [соображения соответствия](troubleshooting.md#recording-disclaimer-for-legal-compliance). Установите соответствующий юридический текст, который отображается перед началом записей. Проконсультируйтесь с местными законами, чтобы обеспечить соответствие — это особенно важно в регионах со строгими законами о записи, таких как ЕС, Калифорния или Австралия.

### Какое лучшее качество аудио для транскрибации?

Записывайте в тихих средах, когда это возможно. Используйте хороший микрофон, расположенный близко к говорящим. Для встреч размещайте записывающее устройство центрально, где все участники четко слышны. Избегайте фоновой музыки или шума телевизора. Более высокое качество аудио не только улучшает точность транскрибации, но и сокращает время обработки и затраты на API.

### Как максимизировать точность транскрибации?

Говорите четко и избегайте перебивать других. Минимизируйте фоновый шум и эхо. Для технического контента рассмотрите добавление пользовательского словаря или глоссария в ваши [промпты](admin-guide/prompts.md). Пользователи могут устанавливать [личные промпты](user-guide/settings.md#custom-prompts-tab) для своих записей. Используйте соответствующую [языковую настройку](user-guide/settings.md#language-preferences), а не полагайтесь на автоматическое определение. Просмотрите [поддержку языков](features.md#language-support) для лучших результатов. Для записей с несколькими говорящими используйте [ASR-эндпоинт](getting-started.md#option-b-custom-asr-endpoint-configuration) с соответствующими настройками количества говорящих. [Идентифицируйте говорящих](user-guide/transcripts.md#speaker-identification) после транскрибации для лучших результатов.

Для китайской транскрибации конкретно используйте модель large-v3, так как меньшие модели могут неправильно выводить китайские символы. Для других языков тестируйте разные модели, чтобы найти лучшую точность для вашего конкретного языка и акцента.

### В чем разница между разделением по размеру и по длительности?

Разделение по размеру файла (например, CHUNK_LIMIT=20MB) хорошо работает для аудио с постоянным битрейтом. Разделение по длительности (например, CHUNK_LIMIT=1400s) лучше, когда ваш сервис транскрибации имеет временные ограничения, такие как максимум 1500 секунд Azure. Разделение на основе длительности гарантирует, что ни одна часть не превышает временной лимит, независимо от сжатия файла или качества.

---

Вернуться на [Главную](index.md) →
